{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "be819da4",
      "metadata": {
        "id": "be819da4"
      },
      "source": [
        "\n",
        "\n",
        "# BERT+CRF_graph_refinement ATE-it\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3578ce17",
      "metadata": {
        "id": "3578ce17"
      },
      "source": [
        "## Install of the required packages for this project\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "94802868",
      "metadata": {
        "id": "94802868"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "!pip install -q pytorch-crf seqeval transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e71e3e6b",
      "metadata": {
        "id": "e71e3e6b"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torchcrf import CRF\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from itertools import combinations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load training set and development set\n"
      ],
      "metadata": {
        "id": "tON7zuRRoR5P"
      },
      "id": "tON7zuRRoR5P"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "def load_jsonl(path: str):\n",
        "    \"\"\"Load a JSON lines file or JSON array file.\"\"\"\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read().strip()\n",
        "    if not text:\n",
        "        return []\n",
        "    try:\n",
        "        data = json.loads(text)\n",
        "    except json.JSONDecodeError:\n",
        "        data = []\n",
        "        for line in text.splitlines():\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                data.append(json.loads(line))\n",
        "    return data\n",
        "\n",
        "\n",
        "def build_sentence_gold_map(records):\n",
        "    \"\"\"Convert dataset rows into list of sentences with aggregated terms.\"\"\"\n",
        "    out = {}\n",
        "\n",
        "    if isinstance(records, dict) and 'data' in records:\n",
        "        rows = records['data']\n",
        "    else:\n",
        "        rows = records\n",
        "\n",
        "    for r in rows:\n",
        "        key = (r.get('document_id'), r.get('paragraph_id'), r.get('sentence_id'))\n",
        "        if key not in out:\n",
        "            out[key] = {\n",
        "                'document_id': r.get('document_id'),\n",
        "                'paragraph_id': r.get('paragraph_id'),\n",
        "                'sentence_id': r.get('sentence_id'),\n",
        "                'sentence_text': r.get('sentence_text', ''),\n",
        "                'terms': []\n",
        "            }\n",
        "\n",
        "        if isinstance(r.get('term_list'), list):\n",
        "            for t in r.get('term_list'):\n",
        "                if t and t not in out[key]['terms']:\n",
        "                    out[key]['terms'].append(t)\n",
        "        else:\n",
        "            term = r.get('term')\n",
        "            if term and term not in out[key]['terms']:\n",
        "                out[key]['terms'].append(term)\n",
        "\n",
        "    return list(out.values())\n",
        "\n",
        "\n",
        "print(\"✓ Data loading functions defined\")\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "train_data = load_jsonl('/content/drive/MyDrive/Colab Notebooks/data/subtask_a_train.json')\n",
        "dev_data = load_jsonl('/content/drive/MyDrive/Colab Notebooks/data/subtask_a_dev.json')\n",
        "\n",
        "train_sentences = build_sentence_gold_map(train_data)\n",
        "dev_sentences = build_sentence_gold_map(dev_data)\n",
        "\n",
        "print(f\"Training sentences: {len(train_sentences)}\")\n",
        "print(f\"Dev sentences: {len(dev_sentences)}\")\n",
        "print(f\"\\nExample sentence:\")\n",
        "print(f\"  Text: {train_sentences[6]['sentence_text']}\")\n",
        "print(f\"  Terms: {train_sentences[6]['terms']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T20eJtOyoXqT",
        "outputId": "22a2c882-17bf-43f9-c3e2-1dba1319d811"
      },
      "id": "T20eJtOyoXqT",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Data loading functions defined\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training sentences: 2308\n",
            "Dev sentences: 577\n",
            "\n",
            "Example sentence:\n",
            "  Text: AFFIDAMENTO DEL “SERVIZIO DI SPAZZAMENTO, RACCOLTA, TRASPORTO E SMALTIMENTO/RECUPERO DEI RIFIUTI URBANI ED ASSIMILATI E SERVIZI COMPLEMENTARI DELLA CITTA' DI AGROPOLI” VALEVOLE PER UN QUINQUENNIO\n",
            "  Terms: ['raccolta', 'recupero', 'servizio di raccolta', 'servizio di spazzamento', 'smaltimento', 'trasporto']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load of Test set"
      ],
      "metadata": {
        "id": "xcaLnyYupJ55"
      },
      "id": "xcaLnyYupJ55"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json, re\n",
        "\n",
        "test_path = \"/content/drive/MyDrive/Colab Notebooks/data/test.json\"\n",
        "\n",
        "# Read file and clean noisy chars\n",
        "with open(test_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    raw = f.read().replace(\"\\ufeff\", \"\").strip()\n",
        "\n",
        "# Extract all JSON objects {...}\n",
        "objects = re.findall(r\"\\{.*?\\}\", raw, flags=re.DOTALL)\n",
        "\n",
        "# Parse each object\n",
        "test_data = []\n",
        "for obj in objects:\n",
        "    try:\n",
        "        test_data.append(json.loads(obj))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "print(\"Loaded entries:\", len(test_data))\n",
        "print(\"Example:\", test_data[0])\n",
        "\n",
        "# Convert to expected model format (no gold terms in test set)\n",
        "test_sentences = [\n",
        "    {\"sentence_text\": x.get(\"sentence_text\", \"\"), \"terms\": []}\n",
        "    for x in test_data\n",
        "]\n",
        "\n",
        "print(\"\\nFormatted example:\", test_sentences[0])\n",
        "print(\"Total:\", len(test_sentences))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m1X_WzMpVCd",
        "outputId": "46e2fc16-63e9-4f03-8761-d57ba681b0ec"
      },
      "id": "7m1X_WzMpVCd",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded entries: 1141\n",
            "Example: {'document_id': 'amato_01', 'paragraph_id': 1, 'sentence_id': 2, 'sentence_text': 'PROVINCIA DI CATANZARO'}\n",
            "\n",
            "Formatted example: {'sentence_text': 'PROVINCIA DI CATANZARO', 'terms': []}\n",
            "Total: 1141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load of training set, development set and test set without mounting the drive\n",
        "(uncomment to use it)"
      ],
      "metadata": {
        "id": "v3KztijptW7J"
      },
      "id": "v3KztijptW7J"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import json, re\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#def upload_and_load_jsonl():\n",
        "#    #Upload a JSONL or JSON array file (train/dev).\n",
        "#    uploaded = files.upload()\n",
        "#    fname = list(uploaded.keys())[0]\n",
        "\n",
        "#    text = open(fname, 'r', encoding='utf-8').read().strip()\n",
        "#    if not text:\n",
        "#        return []\n",
        "\n",
        "#    # JSON array\n",
        "#    try:\n",
        "#        return json.loads(text)\n",
        "#    except json.JSONDecodeError:\n",
        "#        pass\n",
        "\n",
        "#    # JSONL\n",
        "#    data = []\n",
        "#    for line in text.splitlines():\n",
        "#        line = line.strip()\n",
        "#        if line:\n",
        "#            data.append(json.loads(line))\n",
        "#    return data\n",
        "\n",
        "\n",
        "##Training sentences\n",
        "#print(\"Upload TRAIN file:\")\n",
        "#train_raw = upload_and_load_jsonl()\n",
        "#train_sentences = build_sentence_gold_map(train_raw)\n",
        "#print(\"Training sentences:\", len(train_sentences))\n",
        "\n",
        "\n",
        "\n",
        "#\n",
        "##Development senteces\n",
        "#print(\"Upload DEV file:\")\n",
        "#dev_raw = upload_and_load_jsonl()\n",
        "#dev_sentences = build_sentence_gold_map(dev_raw)\n",
        "#print(\"Dev sentences:\", len(dev_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#def upload_and_load_test_sentences():\n",
        "#    \"\"\"\n",
        "#    #Upload a JSON/JSONL/concatenated-JSON test file\n",
        "#    #and convert it into the standard inference format:\n",
        "#        { \"sentence_text\": \"...\", \"terms\": [] }\n",
        "#    \"\"\"\n",
        "#    uploaded = files.upload()\n",
        "#    fname = list(uploaded.keys())[0]\n",
        "\n",
        "#    #  Read raw text\n",
        "#    raw = open(fname, \"r\", encoding=\"utf-8\", errors=\"ignore\").read()\n",
        "#    raw = raw.replace(\"\\ufeff\", \"\").strip()\n",
        "\n",
        "\n",
        "#    #  {…}{…}{…}\n",
        "#    if len(data) == 0:\n",
        "#        blocks = re.findall(r\"\\{.*?\\}\", raw, flags=re.DOTALL)\n",
        "#        for b in blocks:\n",
        "#            try:\n",
        "#                data.append(json.loads(b))\n",
        "#            except:\n",
        "#                pass\n",
        "\n",
        "#    # Convert to model format\n",
        "#    test_sentences = [\n",
        "#        {\n",
        "#            \"sentence_text\": item.get(\"sentence_text\", \"\"),\n",
        "#            \"terms\": []   # TEST SET = no gold labels\n",
        "#        }\n",
        "#        for item in data\n",
        "#    ]\n",
        "\n",
        "#    return test_sentences"
      ],
      "metadata": {
        "id": "m2dudGHxtndG"
      },
      "id": "m2dudGHxtndG",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TYPE METRIC AND MICRO-METRICS FUNCTIONS"
      ],
      "metadata": {
        "id": "MxvEQ0EVveiA"
      },
      "id": "MxvEQ0EVveiA"
    },
    {
      "cell_type": "code",
      "source": [
        "def type_f1_score(gold_standard, system_output):\n",
        "\n",
        "    # gold terms with no repetitions\n",
        "    all_gold_terms = set()\n",
        "    for item_terms in gold_standard:\n",
        "        #normalization\n",
        "        all_gold_terms.update(t.strip().lower() for t in item_terms)\n",
        "\n",
        "    # Predicted terms with no repetitions and normalized\n",
        "    all_system_terms = set()\n",
        "    for item_terms in system_output:\n",
        "        all_system_terms.update(t.strip().lower() for t in item_terms)\n",
        "\n",
        "    type_true_positives = len(all_gold_terms.intersection(all_system_terms))\n",
        "    type_false_positives = len(all_system_terms - all_gold_terms)\n",
        "    type_false_negatives = len(all_gold_terms - all_system_terms)\n",
        "\n",
        "    # Metrics calculations\n",
        "    type_precision = type_true_positives / (type_true_positives + type_false_positives) if (type_true_positives + type_false_positives) > 0 else 0\n",
        "    type_recall = type_true_positives / (type_true_positives + type_false_negatives) if (type_true_positives + type_false_negatives) > 0 else 0\n",
        "    type_f1 = 2 * (type_precision * type_recall) / (type_precision + type_recall) if (type_precision + type_recall) > 0 else 0\n",
        "\n",
        "\n",
        "    print(\"\\n--- TYPE-LEVEL METRICS ---\")\n",
        "    print(f\"Type Precision={type_precision:.4f} Type Recall={type_recall:.4f} Type F1={type_f1:.4f}\")\n",
        "    print(f\"Type TP={type_true_positives}, Type FP={type_false_positives}, Type FN={type_false_negatives}\")\n",
        "\n",
        "    return type_precision, type_recall, type_f1\n",
        "\n",
        "\n",
        "def micro_f1_score(gold_standard, system_output):\n",
        "    gold_s = set()\n",
        "    pred_s = set()\n",
        "\n",
        "\n",
        "    for i, (g, p) in enumerate(zip(gold_standard, system_output)):\n",
        "        for t in g:\n",
        "            gold_s.add((i, t.strip().lower()))\n",
        "        for t in p:\n",
        "            pred_s.add((i, t.strip().lower()))\n",
        "\n",
        "\n",
        "    tp = len(gold_s.intersection(pred_s))\n",
        "    fp = len(pred_s - gold_s)\n",
        "    fn = len(gold_s - pred_s)\n",
        "\n",
        "    # Metrics calculations\n",
        "    P = tp / (tp + fp) if tp + fp > 0 else 0\n",
        "    R = tp / (tp + fn) if tp + fn > 0 else 0\n",
        "    F = 2 * P * R / (P + R) if P + R > 0 else 0\n",
        "\n",
        "\n",
        "    print(\"\\n--- MICRO METRICS ---\")\n",
        "    print(f\"Precision={P:.4f} Type Recall={R:.4f} Type F1={F:.4f}\")\n",
        "    print(f\"Type TP={tp}, Type FP={fp}, Type FN={fn}\")\n",
        "\n",
        "    return P, R, F, tp, fp, fn\n",
        "\n",
        "\n",
        "print(\"✓ Evaluation functions defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNig-VrQw-RZ",
        "outputId": "7920d736-7dfe-42dc-aeac-f739ddb7a3aa"
      },
      "id": "RNig-VrQw-RZ",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Evaluation functions defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ebf6e47",
      "metadata": {
        "id": "0ebf6e47"
      },
      "source": [
        "## Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c0d71a96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0d71a96",
        "outputId": "1c3a5d49-6ccd-4d1d-b585-bec1378623e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "#We use bert-base-italian-cased since the term extraction is on an italian dataset\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-italian-cased\")\n",
        "\n",
        "label_map = {\"O\":0, \"B\":1, \"I\":2}\n",
        "inv_label_map = {v:k for k,v in label_map.items()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea7d56f5",
      "metadata": {
        "id": "ea7d56f5"
      },
      "source": [
        "## Span of the terms within the document\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ad558960",
      "metadata": {
        "id": "ad558960"
      },
      "outputs": [],
      "source": [
        "#Find the index of the span within the document\n",
        "def find_char_spans(sentence, term):\n",
        "    sentence_l = sentence.lower()\n",
        "    term_l = term.lower().strip()\n",
        "\n",
        "    spans = []\n",
        "    start = 0\n",
        "\n",
        "    while True:\n",
        "        idx = sentence_l.find(term_l, start)\n",
        "        if idx == -1:\n",
        "            break\n",
        "        spans.append((idx, idx + len(term_l)))\n",
        "        start = idx + 1\n",
        "\n",
        "    return spans\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f4b1ef5",
      "metadata": {
        "id": "5f4b1ef5"
      },
      "source": [
        "## Tagging of the sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "98e101e4",
      "metadata": {
        "id": "98e101e4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def encode_with_BIO_labels(sentence, terms, tokenizer):\n",
        "    enc = tokenizer(sentence, return_offsets_mapping=True, add_special_tokens=False)\n",
        "    offsets = enc[\"offset_mapping\"]\n",
        "    input_ids = enc[\"input_ids\"]\n",
        "    labels = [label_map[\"O\"]] * len(input_ids) # Initialize everything as 'O'\n",
        "\n",
        "    for term in terms:\n",
        "        spans = find_char_spans(sentence, term)\n",
        "        for (start_c, end_c) in spans:\n",
        "            in_entity = False\n",
        "            for i, (s, e) in enumerate(offsets):\n",
        "\n",
        "                #if it is in the left\n",
        "                if e <= start_c: continue\n",
        "                # if it is in the right\n",
        "                if s >= end_c: break\n",
        "\n",
        "                # if the token is within the term\n",
        "\n",
        "\n",
        "                if not in_entity:\n",
        "                    labels[i] = label_map[\"B\"]\n",
        "                    in_entity = True # From here on we are inside the entity\n",
        "                else:\n",
        "                    labels[i] = label_map[\"I\"]\n",
        "\n",
        "    return input_ids, labels, offsets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c2d847f",
      "metadata": {
        "id": "2c2d847f"
      },
      "source": [
        "## Function to encode the data (sentences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9fe8e4c9",
      "metadata": {
        "id": "9fe8e4c9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def encode_for_inference(sentence, tokenizer):\n",
        "    enc = tokenizer(sentence, return_offsets_mapping=True, add_special_tokens=False) #we mantain the indices of the subtokens\n",
        "    return enc[\"input_ids\"], enc[\"offset_mapping\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42f03388",
      "metadata": {
        "id": "42f03388"
      },
      "source": [
        "## Custom Dataset and dynamic padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "535a3780",
      "metadata": {
        "id": "535a3780"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#Class to develop interface between preprocessed data and PyTorch's DataLoader\n",
        "class BIO_Dataset(Dataset):\n",
        "    def __init__(self, data): self.data = data\n",
        "    def __len__(self): return len(self.data)\n",
        "    def __getitem__(self, idx): return self.data[idx]\n",
        "\n",
        "\n",
        "#Function to make each sentence have the same length within the batch\n",
        "def pad_batch(batch):\n",
        "    max_len = max(len(x[\"input_ids\"]) for x in batch)\n",
        "    ids=[]; labs=[]; mask=[]\n",
        "    for x in batch:\n",
        "        L=len(x[\"input_ids\"])\n",
        "        pad=max_len-L\n",
        "        ids.append(x[\"input_ids\"] + [0]*pad)\n",
        "        labs.append(x[\"labels\"] + [0]*pad)\n",
        "        mask.append([1]*L + [0]*pad)\n",
        "    return {\n",
        "        \"input_ids\": torch.tensor(ids),\n",
        "        \"labels\": torch.tensor(labs),\n",
        "        \"attention_mask\": torch.tensor(mask)\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "060c539d",
      "metadata": {
        "id": "060c539d"
      },
      "source": [
        "## BERT + Conditional Random Field layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "75e935d7",
      "metadata": {
        "id": "75e935d7"
      },
      "outputs": [],
      "source": [
        "#In this cell we define the model we are going to use to predict the terms\n",
        "\n",
        "class BERT_CRF(nn.Module):\n",
        "    def __init__(self, model_name=\"dbmdz/bert-base-italian-cased\", num_labels=3):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels) #Linear layer to go from dimension of bert (768) to the number of labels(3 BIO)\n",
        "        self.crf = CRF(num_labels, batch_first=True) #CRF models the probability of transitions between tags (generate some consistency)\n",
        "\n",
        "    def forward(self, ids, mask, labels=None):\n",
        "        out = self.bert(input_ids=ids, attention_mask=mask)\n",
        "        logits = self.classifier(out.last_hidden_state)\n",
        "        if labels is not None:\n",
        "            loss = -self.crf(logits, labels, mask=mask.bool(), reduction=\"mean\")\n",
        "            return loss\n",
        "        else:\n",
        "            return self.crf.decode(logits, mask=mask.bool())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9fba2d2",
      "metadata": {
        "id": "d9fba2d2"
      },
      "source": [
        "## Training Phase\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a93641cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a93641cf",
        "outputId": "bb680e45-4f6f-4b12-96bc-a89d2af39f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Loss: 6.3372\n",
            "Epoch 2/5 - Loss: 2.6092\n",
            "Epoch 3/5 - Loss: 1.4819\n",
            "Epoch 4/5 - Loss: 0.9391\n",
            "Epoch 5/5 - Loss: 0.6060\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Encoding of sentences from the training set\n",
        "encoded_train=[]\n",
        "for s in train_sentences:\n",
        "    ids, labs, off = encode_with_BIO_labels(s[\"sentence_text\"], s.get(\"terms\",[]), tokenizer)\n",
        "    encoded_train.append({\"input_ids\": ids, \"labels\": labs})\n",
        "\n",
        "# Encoding of sentences from the development set\n",
        "encoded_dev=[]\n",
        "for s in dev_sentences:\n",
        "    ids, labs, off = encode_with_BIO_labels(s[\"sentence_text\"], s.get(\"terms\",[]), tokenizer)\n",
        "    encoded_dev.append({\"input_ids\": ids, \"labels\": labs})\n",
        "\n",
        "# Data loading\n",
        "train_loader = DataLoader(BIO_Dataset(encoded_train), batch_size=8, shuffle=True, collate_fn=pad_batch)\n",
        "dev_loader   = DataLoader(BIO_Dataset(encoded_dev),   batch_size=8, shuffle=False, collate_fn=pad_batch)\n",
        "\n",
        "\n",
        "# Setup of the device used\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model=BERT_CRF().to(device)\n",
        "\n",
        "# Discriminative learning rate\n",
        "bert_lr = 3.7e-5    # Learning rate for Bert, small in order to mantain enough knowledge\n",
        "new_layers_lr = 1e-3 # For last layers the learning rate must be higher in order to learn in 5 epochs enough patterns\n",
        "\n",
        "\n",
        "# Group parameters on the basis of the learning rate to use\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': model.bert.parameters(), 'lr': bert_lr},\n",
        "    {'params': list(model.classifier.parameters()) + list(model.crf.parameters()), 'lr': new_layers_lr},\n",
        "]\n",
        "\n",
        "#use AdamW to prevent overfitting issues\n",
        "optimizer=torch.optim.AdamW(optimizer_grouped_parameters)\n",
        "\n",
        "\n",
        "epochs = 5 #epochs used for the training\n",
        "for ep in range(epochs):\n",
        "    model.train()\n",
        "    tot=0\n",
        "    for batch in train_loader:\n",
        "        ids=batch[\"input_ids\"].to(device)\n",
        "        labs=batch[\"labels\"].to(device)\n",
        "        mask=batch[\"attention_mask\"].to(device)\n",
        "\n",
        "        # Forward Pass\n",
        "        loss=model(ids,mask,labs)\n",
        "\n",
        "        # Backward Pass\n",
        "        optimizer.zero_grad() #to prevent accumulations of gradients\n",
        "        loss.backward()\n",
        "        optimizer.step() # update weights\n",
        "        tot+=loss.item()\n",
        "\n",
        "    print(f\"Epoch {ep+1}/{epochs} - Loss: {tot/len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f718ac6",
      "metadata": {
        "id": "2f718ac6"
      },
      "source": [
        "## Save the Model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "576b435e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "576b435e",
        "outputId": "3ce48450-2e76-43d0-f3bb-832f9c129532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Encoder BERT_CRF saved in: models/crf_encoder_best\n"
          ]
        }
      ],
      "source": [
        "\n",
        "crf_encoder_dir = \"models/crf_encoder_best\"\n",
        "\n",
        "# Save the encoder and the tokenizer in Hugging Face format\n",
        "# Later they will be used for the graph enhancement part\n",
        "model.bert.save_pretrained(crf_encoder_dir)\n",
        "tokenizer.save_pretrained(crf_encoder_dir)\n",
        "\n",
        "print(f\"✓ Encoder BERT_CRF saved in: {crf_encoder_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb511004",
      "metadata": {
        "id": "eb511004"
      },
      "source": [
        "## From BIO tags to terms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "56af9877",
      "metadata": {
        "id": "56af9877"
      },
      "outputs": [],
      "source": [
        "\n",
        "def bio_to_terms(sentence, offsets, pred_ids):\n",
        "    spans=[]\n",
        "    cur=[]\n",
        "    for (s,e),lab in zip(offsets, pred_ids): # couple the id of each subtoken with its ID\n",
        "        tag=inv_label_map[lab] # from ID to TAG\n",
        "        if tag==\"B\": # beginning of the term\n",
        "            if cur: spans.append(cur)\n",
        "            cur=[(s,e)]\n",
        "        elif tag==\"I\" and cur:\n",
        "            cur.append((s,e))\n",
        "        else:\n",
        "            if cur: spans.append(cur) # end of the term\n",
        "            cur=[]\n",
        "    if cur: spans.append(cur)\n",
        "\n",
        "    terms=[]\n",
        "    for toks in spans: # iterates on the spans reconstructed\n",
        "        st=toks[0][0]; en=toks[-1][1] # Impose the start on the first character of first subtoken and the end on the last character of last subtoken\n",
        "        terms.append(sentence[st:en]) # Based on the indices obtained extract the term  from the original sentence and append to terms list\n",
        "\n",
        "    return terms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4554bdbd",
      "metadata": {
        "id": "4554bdbd"
      },
      "source": [
        "## Inference on development set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3632d5ba",
      "metadata": {
        "id": "3632d5ba"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "crf_predictions=[] # list of terms that will be extracted\n",
        "model.eval() # evaluation mode\n",
        "with torch.no_grad(): # no gradient calculations to reduce computational time\n",
        "    for s in dev_sentences:\n",
        "        ids, offsets = encode_for_inference(s[\"sentence_text\"], tokenizer) # Data preprocessing\n",
        "        inp=torch.tensor([ids]).to(device) # Tranform into a tensor in order to work with GPU\n",
        "        mask=torch.tensor([[1]*len(ids)]).to(device)\n",
        "        pred = model(inp,mask)[0] #prediction of sequence of tags\n",
        "        crf_predictions.append(bio_to_terms(s[\"sentence_text\"], offsets, pred)) # we populate the list of terms predicted after transforming them using the function defined previously\n",
        "\n",
        "#crf_predictions will be the input for the construction of the graph to refine the method\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1916af0f",
      "metadata": {
        "id": "1916af0f"
      },
      "source": [
        "## Evaluation of the predictions on the Development set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d364405f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d364405f",
        "outputId": "9eca048d-a99b-40aa-a750-e8110de19712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TYPE-LEVEL METRICS ---\n",
            "Type Precision=0.6777 Type Recall=0.5909 Type F1=0.6313\n",
            "Type TP=143, Type FP=68, Type FN=99\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7297 Type Recall=0.6763 Type F1=0.7020\n",
            "Type TP=305, Type FP=113, Type FN=146\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7296650717703349, 0.6762749445676275, 0.7019562715765248, 305, 113, 146)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\n",
        "#It appears that the optimal learning rates are 3.7e-5 for bert and 1e-3 for CRF while I used 5 epochs\n",
        "\n",
        "#Type_f1_score\n",
        "type_f1_score([s[\"terms\"] for s in dev_sentences], crf_predictions)\n",
        "\n",
        "#Micro metrics\n",
        "micro_f1_score([s[\"terms\"] for s in dev_sentences], crf_predictions)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8fb3f7c",
      "metadata": {
        "id": "b8fb3f7c"
      },
      "source": [
        "## Post-Processing refinements\n",
        "\n",
        "This section describes an enhancement for the BERT+CRF model. I first constructed a co-occurence graph based on the gold terms of training data which later I augmented by exploiting syntactic relations obtained using Spacy. Eventually I calculated Page rank centrality in order to define global domain importance. <br>\n",
        "Simultaneously I enriched the domain vocabulary by using a few-shot prompting technique using Groq. The LLM was instructed to extract terms regarding waste management from an external corpora. In particular I used \"Parte IV del D.Lgs. 152/2006\". In order to obtain even more remarkable results one may augment the corpora by including other legislative documents regarding the domain of interest. The terms extracted were used along with gold term of the training set to define an embedding space that was used to compute similarity with the terms found at inference time. <br>\n",
        "In the end I implemented a hybrid filtering score combining Graph Centrality (PageRank) with a weight of $\\mathbf{0.4}$ and Semantic Similarity (from our augmented embedding space) with a weight of $\\mathbf{1-\\alpha=0.6}$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2ae490b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ae490b2",
        "outputId": "19197f5d-ae2e-4e53-a3f9-28c9782d92db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building term co-occurrence graph from TRAIN gold terms...\n",
            "Graph built: 713 nodes, 1451 edges\n",
            "Computing PageRank centrality over term graph...\n",
            "PageRank centrality computed\n",
            "Centrality range: min=0.000258, max=0.022605\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import networkx as nx\n",
        "\n",
        "def normalize_term(t: str) -> str:\n",
        "    return t.strip().lower()\n",
        "\n",
        "print(\"Building term co-occurrence graph from TRAIN gold terms...\")\n",
        "\n",
        "G = nx.Graph()\n",
        "\n",
        "for sent in train_sentences:\n",
        "    raw_terms = sent.get('terms', [])\n",
        "    terms = [normalize_term(t) for t in raw_terms if t and t.strip()]\n",
        "    unique_terms = list(set(terms))\n",
        "    if not unique_terms:\n",
        "        continue\n",
        "\n",
        "    # add or update nodes\n",
        "    for term in unique_terms:\n",
        "        if term not in G:\n",
        "            G.add_node(term, freq=0)\n",
        "        G.nodes[term]['freq'] += 1\n",
        "\n",
        "    # add or update edges for co-occurring terms\n",
        "    from itertools import combinations\n",
        "    for t1, t2 in combinations(unique_terms, 2):\n",
        "        if G.has_edge(t1, t2):\n",
        "            G[t1][t2]['weight'] += 1\n",
        "        else:\n",
        "            G.add_edge(t1, t2, weight=1)\n",
        "\n",
        "print(f\"Graph built: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
        "#how important is each node in the graph (is a recursive importance measure)\n",
        "print(\"Computing PageRank centrality over term graph...\")\n",
        "centrality = nx.pagerank(G, weight='weight')\n",
        "print(\"PageRank centrality computed\")\n",
        "\n",
        "# pre-compute min/max centrality for normalization\n",
        "c_values = np.array(list(centrality.values()))\n",
        "c_min = float(c_values.min()) if len(c_values) > 0 else 0.0\n",
        "c_max = float(c_values.max()) if len(c_values) > 0 else 1.0\n",
        "eps = 1e-8 # to prevent division by zero\n",
        "print(f\"Centrality range: min={c_min:.6f}, max={c_max:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39a00741",
      "metadata": {
        "id": "39a00741"
      },
      "source": [
        "## Syntactic enhancement of the Graph by using Spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c8cd1ed7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8cd1ed7",
        "outputId": "db9ceefc-6819-4aba-85da-443dd87e087b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting it-core-news-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_lg-3.8.0/it_core_news_lg-3.8.0-py3-none-any.whl (567.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.9/567.9 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Enhancing existing term graph with spaCy syntactic information...\n",
            " spaCy enhancement completed.\n",
            "Graph now: 713 nodes, 1451 edges\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python -m spacy download it_core_news_lg\n",
        "import spacy\n",
        "nlp = spacy.load(\"it_core_news_lg\")\n",
        "\n",
        "print(\"Enhancing existing term graph with spaCy syntactic information...\")\n",
        "\n",
        "for sent in train_sentences:\n",
        "    text = sent[\"sentence_text\"]\n",
        "    raw_terms = sent.get(\"terms\", [])\n",
        "    terms = [normalize_term(t) for t in raw_terms if t and t.strip()]\n",
        "\n",
        "    # there has to be at least a pair of words in the term\n",
        "    if len(terms) < 2:\n",
        "        continue\n",
        "\n",
        "    # lemmatize all the terms\n",
        "    term_lemmas = {\n",
        "        t: \" \".join(tok.lemma_.lower() for tok in nlp(t))\n",
        "        for t in terms\n",
        "    }\n",
        "\n",
        "    # parse the document\n",
        "    doc = nlp(text)\n",
        "\n",
        "\n",
        "    #for each record the positions of tokens which match the lemma\n",
        "    term_positions = {}\n",
        "    for t, lemma in term_lemmas.items():\n",
        "        lemma_head = lemma.split()[0]\n",
        "        pos = [token.i for token in doc if token.lemma_.lower() == lemma_head]\n",
        "        if pos:\n",
        "            term_positions[t] = pos\n",
        "\n",
        "    # enhancement term-term\n",
        "    from itertools import combinations\n",
        "    for t1, t2 in combinations(term_positions.keys(), 2):\n",
        "        pos1 = term_positions[t1]\n",
        "        pos2 = term_positions[t2]\n",
        "\n",
        "        # define minimum distance between two terms\n",
        "        min_dist = min(abs(a - b) for a in pos1 for b in pos2)\n",
        "\n",
        "        # heuristics rules to change edge weights\n",
        "        if min_dist <= 2:\n",
        "            w = 15\n",
        "        elif min_dist <= 5:\n",
        "            w = 10\n",
        "        else:\n",
        "            w = 1\n",
        "\n",
        "        # update weights\n",
        "        if G.has_edge(t1, t2):\n",
        "            G[t1][t2]['weight'] += w\n",
        "        else:\n",
        "            G.add_edge(t1, t2, weight=w)\n",
        "\n",
        "        # Since it is a non oriented graph we have to update both directions\n",
        "        if G.has_edge(t2, t1):\n",
        "            G[t2][t1]['weight'] += w\n",
        "        else:\n",
        "            G.add_edge(t2, t1, weight=w)\n",
        "\n",
        "print(\" spaCy enhancement completed.\")\n",
        "print(f\"Graph now: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "388b0400",
      "metadata": {
        "id": "388b0400"
      },
      "source": [
        "## Recompute the centrality values after the syntactic enhancement\n",
        "\n",
        "Actually the enhancement does not improve too much the centrality values since the documents are often short. This would work better if there were multiple terms within the same document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "206684bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "206684bc",
        "outputId": "f34af204-a966-40e8-f876-b15a419d91b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recomputing PageRank after spaCy enhancement...\n",
            "PageRank recalculated with updated graph\n",
            "New centrality range: 0.0002576876825291253 to 0.02157409729729366\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "print(\"Recomputing PageRank after spaCy enhancement...\")\n",
        "\n",
        "centrality = nx.pagerank(G, weight=\"weight\")\n",
        "c_values = np.array(list(centrality.values()))\n",
        "c_min = float(c_values.min()) if len(c_values)>0 else 0.0\n",
        "c_max = float(c_values.max()) if len(c_values)>0 else 1.0\n",
        "\n",
        "print(\"PageRank recalculated with updated graph\")\n",
        "print(\"New centrality range:\", c_min, \"to\", c_max)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04c078de",
      "metadata": {
        "id": "04c078de"
      },
      "source": [
        "## Collect domain terms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e73a29a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e73a29a7",
        "outputId": "ca770bc0-b983-4606-f128-991da1cc03d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial domain terms from PageRank graph: 713\n"
          ]
        }
      ],
      "source": [
        "domain_terms = list(centrality.keys())\n",
        "print(f\"Initial domain terms from PageRank graph: {len(domain_terms)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ce9810a",
      "metadata": {
        "id": "5ce9810a"
      },
      "source": [
        "## Few shot prompting using Groq LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6ab0b63e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ab0b63e",
        "outputId": "2de23cb4-ea5a-426f-d46a-80b5894e8a79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loaded document with 334964 characters split into 42 chunks.\n",
            "\n",
            "--- Processing chunk 1/42 ---\n",
            "Extracted 20 terms from chunk 1\n",
            "\n",
            "--- Processing chunk 2/42 ---\n",
            "Extracted 21 terms from chunk 2\n",
            "\n",
            "--- Processing chunk 3/42 ---\n",
            "Extracted 12 terms from chunk 3\n",
            "\n",
            "--- Processing chunk 4/42 ---\n",
            "Extracted 31 terms from chunk 4\n",
            "\n",
            "--- Processing chunk 5/42 ---\n",
            "Extracted 44 terms from chunk 5\n",
            "\n",
            "--- Processing chunk 6/42 ---\n",
            "Extracted 22 terms from chunk 6\n",
            "\n",
            "--- Processing chunk 7/42 ---\n",
            "Extracted 21 terms from chunk 7\n",
            "\n",
            "--- Processing chunk 8/42 ---\n",
            "Extracted 26 terms from chunk 8\n",
            "\n",
            "--- Processing chunk 9/42 ---\n",
            "Extracted 17 terms from chunk 9\n",
            "\n",
            "--- Processing chunk 10/42 ---\n",
            "Extracted 56 terms from chunk 10\n",
            "\n",
            "--- Processing chunk 11/42 ---\n",
            "Extracted 46 terms from chunk 11\n",
            "\n",
            "--- Processing chunk 12/42 ---\n",
            "Extracted 17 terms from chunk 12\n",
            "\n",
            "--- Processing chunk 13/42 ---\n",
            "Extracted 17 terms from chunk 13\n",
            "\n",
            "--- Processing chunk 14/42 ---\n",
            "Extracted 46 terms from chunk 14\n",
            "\n",
            "--- Processing chunk 15/42 ---\n",
            "Extracted 27 terms from chunk 15\n",
            "\n",
            "--- Processing chunk 16/42 ---\n",
            "Extracted 44 terms from chunk 16\n",
            "\n",
            "--- Processing chunk 17/42 ---\n",
            "Extracted 30 terms from chunk 17\n",
            "\n",
            "--- Processing chunk 18/42 ---\n",
            "Extracted 13 terms from chunk 18\n",
            "\n",
            "--- Processing chunk 19/42 ---\n",
            "Extracted 9 terms from chunk 19\n",
            "\n",
            "--- Processing chunk 20/42 ---\n",
            "Extracted 21 terms from chunk 20\n",
            "\n",
            "--- Processing chunk 21/42 ---\n",
            "Extracted 38 terms from chunk 21\n",
            "\n",
            "--- Processing chunk 22/42 ---\n",
            "Extracted 42 terms from chunk 22\n",
            "\n",
            "--- Processing chunk 23/42 ---\n",
            "Extracted 30 terms from chunk 23\n",
            "\n",
            "--- Processing chunk 24/42 ---\n",
            "Extracted 21 terms from chunk 24\n",
            "\n",
            "--- Processing chunk 25/42 ---\n",
            "Extracted 31 terms from chunk 25\n",
            "\n",
            "--- Processing chunk 26/42 ---\n",
            "Extracted 19 terms from chunk 26\n",
            "\n",
            "--- Processing chunk 27/42 ---\n",
            "Extracted 36 terms from chunk 27\n",
            "\n",
            "--- Processing chunk 28/42 ---\n",
            "Extracted 18 terms from chunk 28\n",
            "\n",
            "--- Processing chunk 29/42 ---\n",
            "Extracted 51 terms from chunk 29\n",
            "\n",
            "--- Processing chunk 30/42 ---\n",
            "Extracted 11 terms from chunk 30\n",
            "\n",
            "--- Processing chunk 31/42 ---\n",
            "Extracted 12 terms from chunk 31\n",
            "\n",
            "--- Processing chunk 32/42 ---\n",
            "Extracted 32 terms from chunk 32\n",
            "\n",
            "--- Processing chunk 33/42 ---\n",
            "Extracted 25 terms from chunk 33\n",
            "\n",
            "--- Processing chunk 34/42 ---\n",
            "Extracted 16 terms from chunk 34\n",
            "\n",
            "--- Processing chunk 35/42 ---\n",
            "Extracted 18 terms from chunk 35\n",
            "\n",
            "--- Processing chunk 36/42 ---\n",
            "Extracted 25 terms from chunk 36\n",
            "\n",
            "--- Processing chunk 37/42 ---\n",
            "Extracted 12 terms from chunk 37\n",
            "\n",
            "--- Processing chunk 38/42 ---\n",
            "Extracted 19 terms from chunk 38\n",
            "\n",
            "--- Processing chunk 39/42 ---\n",
            "Extracted 32 terms from chunk 39\n",
            "\n",
            "--- Processing chunk 40/42 ---\n",
            "Extracted 26 terms from chunk 40\n",
            "\n",
            "--- Processing chunk 41/42 ---\n",
            "Extracted 12 terms from chunk 41\n",
            "\n",
            "--- Processing chunk 42/42 ---\n",
            "Extracted 16 terms from chunk 42\n",
            "\n",
            "=== FINAL GROQ TERM LIST ===\n",
            "Total extracted terms: 654\n",
            "['(non è presente)', '- acque di falda', '- acque reflue', '- acque reflue industriali', '- acque superficiali', '- analisi di rischio', '- aree contaminati', '- assimilazione dei rifiuti speciali non pericolosi ai rifiuti urbani', '- autocertificazione', '- biogas', '- biogas e biometano', '- biogas e biometano:', '- biometano', '- bonifica', '- bonificabilità', '- caratterizzazione', '- combustibile da rifiuti', '- combustibile da rifiuti di qualità elevata (cdr-q)', '- combustione', '- combustione controllata', '- concentrazione soglia di contaminazione', '- concentrazioni soglia di rischio (csr)', '- conferimento, raccolta differenziata e trasporto dei rifiuti urbani', '- contaminazione', '- contaminazione storica', '- csc (concentrazioni soglia di contaminazione)', '- css', \"- destinazione d'uso\", '- digestione', '- digestione anaerobica', '- digestione anaerobica (non presente)', '- digestione anaerobica:', '- discarica', '- discarica di rifiuti', '- discariche', '- discariche controllate', '- disidratazione meccanica', '- effettivo utilizzo', '- end of waste', '- end of waste (eow)', '- end of waste (eow):', '- fabbisogno di manufatti e beni', '- fanghi', '- fanghi di depurazione', '- fanghi di depurazione:', '- fonti inquinanti', '- forsu', '- forsu e compostaggio', '- gestione dei rifiuti urbani', '- impianti di recupero dei rifiuti']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Since the API key is personal and I cannot publish it I will save the terms in a document that later can be reused, at each run the LLM may extract different terms.\n",
        "\n",
        "#Create a semantic space by using Groq LLM to extract terms (using prompting) from a text with similar domain to the training set then i will create encodings of those terms\n",
        "#os.environ['GROQ_API_KEY'] = \"g\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install -q groq\n",
        "\n",
        "import os\n",
        "from groq import Groq\n",
        "\n",
        "\n",
        "# Set your Groq API key here or via environment\n",
        "os.environ['GROQ_API_KEY'] = \"\"\n",
        "client = Groq(api_key=os.environ['GROQ_API_KEY'])\n",
        "\n",
        "# Path to the uploaded file\n",
        "extra_doc_path = \"/content/drive/MyDrive/Colab Notebooks/data/DLgs_152_partequarta.txt\"\n",
        "\n",
        "\n",
        "# Split long text into manageable LLM chunks\n",
        "\n",
        "def chunk_text(text, max_chars=8000):\n",
        "\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = min(start + max_chars, len(text))\n",
        "        chunks.append(text[start:end])\n",
        "        start = end\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# Load the file and chunk it\n",
        "with open(extra_doc_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    full_text = f.read()\n",
        "\n",
        "chunks = chunk_text(full_text, max_chars=8000)\n",
        "print(f\"Loaded document with {len(full_text)} characters split into {len(chunks)} chunks.\")\n",
        "\n",
        "\n",
        "\n",
        "# Groq prompting for each chunk\n",
        "extra_terms = []\n",
        "\n",
        "# The prompt is in italian for better accuracy\n",
        "\n",
        "prompt_template = \"\"\"  Sei un estrattore di termini tecnici del dominio “gestione dei rifiuti”.\n",
        "Dato un testo, estrai SOLO i termini specialistici rilevanti per:\n",
        "- rifiuti urbani\n",
        "- rifiuti speciali\n",
        "- rifiuti pericolosi\n",
        "- fanghi di depurazione\n",
        "- FORSU e compostaggio\n",
        "- digestione anaerobica\n",
        "- biogas e biometano\n",
        "- impianti di trattamento meccanico-biologico (TMB)\n",
        "- End of Waste (EoW)\n",
        "- discariche controllate\n",
        "- RAEE\n",
        "- recupero energetico e CSS/CSS-combustibile\n",
        "\n",
        "REGOLE IMPORTANTI:\n",
        "1. Restituisci solamente il termine, uno per riga.\n",
        "2. Usa solo termini tecnici e specifici (no parole generiche).\n",
        "3. Mantieni i termini nel formato originale (minuscolo/maiuscolo non importa).\n",
        "4. Se un concetto ha più parole, mantienilo come un unico termine composito (es. “digestione anaerobica”, “captazione biogas”).\n",
        "5. Solitamente i termini non sono molto lunghi, genera al massimo termini fino a 4 o 5 parole. Non inserire punteggiatura e parentesi.\n",
        "6. Non generare niente di tua spontanea volontà ma riporta soltanto termini che pensi facciano parte del dominio prendendoli dal testo. Se non trovi nulla non inserire nulla.\n",
        "\n",
        "Esempi:\n",
        "\n",
        "ESEMPIO 1 – Input:\n",
        "“La FORSU viene avviata a un processo di digestione anaerobica in reattori termofili,\n",
        "con produzione di biogas successivamente inviato a sistemi di upgrading.”\n",
        "\n",
        "Output:\n",
        "forsu\n",
        "digestione anaerobica\n",
        "reattori termofili\n",
        "biogas\n",
        "upgrading\n",
        "\n",
        "ESEMPIO 2 – Input:\n",
        "“I fanghi di depurazione subiscono ispessimento, digestione e disidratazione tramite centrifughe.”\n",
        "\n",
        "Output:\n",
        "fanghi di depurazione\n",
        "ispessimento\n",
        "digestione dei fanghi\n",
        "disidratazione meccanica\n",
        "centrifughe\n",
        "\n",
        "ESEMPIO 3 – Input:\n",
        "“Il CSS viene valorizzato in impianti di recupero energetico tramite combustione controllata.”\n",
        "\n",
        "Output:\n",
        "css\n",
        "recupero energetico\n",
        "combustione controllata\n",
        "\n",
        "---\n",
        "\n",
        "Come hai visto dagli esempi non aggiungere nessuna parola in più, nemmeno tra parentesi, riporta solo dal testo e non individuare termini troppo lunghi.\n",
        "\n",
        "ORA ESTRARRE I TERMINI DAL SEGUENTE TESTO:\n",
        "\n",
        "{chunk}\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "for idx, chunk in enumerate(chunks):\n",
        "    print(f\"\\n--- Processing chunk {idx+1}/{len(chunks)} ---\")\n",
        "\n",
        "    prompt = prompt_template.format(chunk=chunk)\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "\n",
        "    raw = resp.choices[0].message.content\n",
        "\n",
        "    # Parse returned terms\n",
        "    chunk_terms = [\n",
        "        x.strip().lower()\n",
        "        for x in raw.split(\"\\n\")\n",
        "        if len(x.strip()) > 2\n",
        "    ]\n",
        "\n",
        "    print(f\"Extracted {len(chunk_terms)} terms from chunk {idx+1}\")\n",
        "    extra_terms.extend(chunk_terms)\n",
        "\n",
        "\n",
        "# Final cleanup: deduplicate, remove junk, sort\n",
        "\n",
        "extra_terms = sorted(list(set(extra_terms)))\n",
        "extra_terms = [t for t in extra_terms if not t.isnumeric() and len(t) > 1]\n",
        "\n",
        "print(\"\\n=== FINAL GROQ TERM LIST ===\")\n",
        "print(f\"Total extracted terms: {len(extra_terms)}\")\n",
        "print(extra_terms[:50])  # show a preview\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save the terms found in a json file"
      ],
      "metadata": {
        "id": "dCMqydsqSMIA"
      },
      "id": "dCMqydsqSMIA"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "output_file_path = \"/content/drive/MyDrive/Colab Notebooks/data/groq_extra_terms.json\" # you may have to change the path\n",
        "\n",
        "print(f\"\\nSaving {len(extra_terms)} unique terms to {output_file_path} in JSON format...\")\n",
        "\n",
        "try:\n",
        "    with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(extra_terms, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"Terms saved\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during saving: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG9o6mh1SWDn",
        "outputId": "0a3e5ae4-65a9-4757-e1f7-eceb2ed3e7b3"
      },
      "id": "TG9o6mh1SWDn",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving 654 unique terms to /content/drive/MyDrive/Colab Notebooks/data/groq_extra_terms.json in JSON format...\n",
            "Terms saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extract the terms found by the LLM\n",
        "In order not to recompute them each time upload the terms previously found"
      ],
      "metadata": {
        "id": "XZ4dj5jISkJL"
      },
      "id": "XZ4dj5jISkJL"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import json\n",
        "output_file_path = \"/content/drive/MyDrive/Colab Notebooks/data/groq_extra_terms.json\" # you may have to change the path\n",
        "extra_terms = []\n",
        "\n",
        "print(f\"Taking terms from {output_file_path}...\")\n",
        "\n",
        "try:\n",
        "    with open(output_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        extra_terms = json.load(f)\n",
        "\n",
        "    print(f\"Loaded {len(extra_terms)} terms.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERRORE: File JSON not found in: {output_file_path}. Make sure you have used the prompting cell at least once.\")\n",
        "except Exception as e:\n",
        "    print(f\"ERRORE in parsing json file: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqjBKTjQSyKS",
        "outputId": "d9382251-6525-454b-d3fd-e4f20aa30c86"
      },
      "id": "mqjBKTjQSyKS",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taking terms from /content/drive/MyDrive/Colab Notebooks/data/groq_extra_terms.json...\n",
            "Loaded 654 terms.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4214fd3f",
      "metadata": {
        "id": "4214fd3f"
      },
      "source": [
        "## Encode domain terms and terms found by the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "fda73e82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fda73e82",
        "outputId": "db687739-b9cd-4b1f-aeb1-39a2205f9978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device for embeddings: cuda\n",
            "Loading encoder model for term embeddings...\n",
            "Encoder loaded\n",
            "Total domain terms for embedding space: 1342\n",
            "Encoding all domain terms into embeddings...\n",
            "domain_embs ready with shape: (1342, 768)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "crf_encoder_dir = \"models/crf_encoder_best\"\n",
        "\n",
        "from transformers import AutoModel\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device for embeddings:\", device)\n",
        "\n",
        "# Load the encoder\n",
        "print(\"Loading encoder model for term embeddings...\")\n",
        "\n",
        "inference_tokenizer = AutoTokenizer.from_pretrained(crf_encoder_dir)\n",
        "embed_model = AutoModel.from_pretrained(crf_encoder_dir).to(device)\n",
        "embed_model.eval()\n",
        "print(\"Encoder loaded\")\n",
        "\n",
        "\n",
        "def encode_terms(term_list):\n",
        "    if not term_list:\n",
        "        return np.zeros((0, embed_model.config.hidden_size), dtype=np.float32)\n",
        "    enc = inference_tokenizer(\n",
        "        term_list,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        outputs = embed_model(\n",
        "            input_ids=enc['input_ids'].to(device),\n",
        "            attention_mask=enc['attention_mask'].to(device)\n",
        "        )\n",
        "        # CLS pooling\n",
        "        cls = outputs.last_hidden_state[:, 0, :]  # [B, H]\n",
        "        cls = F.normalize(cls, p=2, dim=-1) # L2 normalization\n",
        "    return cls.cpu().numpy()\n",
        "\n",
        "# Generatin the embeddings of domain terms and Groq-augmented terms\n",
        "domain_terms = list(centrality.keys())\n",
        "all_terms = list(set(domain_terms + extra_terms))\n",
        "print(\"Total domain terms for embedding space:\", len(all_terms))\n",
        "\n",
        "print(\"Encoding all domain terms into embeddings...\")\n",
        "domain_embs = encode_terms(all_terms)\n",
        "print(\"domain_embs ready with shape:\", domain_embs.shape)\n",
        "# Keep all_terms as the list aligned with domain_embs rows\n",
        "domain_terms = all_terms\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffacad6b",
      "metadata": {
        "id": "ffacad6b"
      },
      "source": [
        "## Function that refines predictions\n",
        "\n",
        "This function blend the logic of Page Rank with the embedding space logic and it's actually the bottleneck filter of the refinement method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a6113ed2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6113ed2",
        "outputId": "175af12a-d75f-44b1-bd5c-e318f9aee920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refinement function with graph + embeddings defined\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Refine predicted term lists\n",
        "def refine_predictions_with_graph_and_embeddings(\n",
        "    predictions,\n",
        "    centrality,\n",
        "    quantile: float = 0.1,\n",
        "    alpha: float = 0.4\n",
        "):\n",
        "\n",
        "#predictions: list[list[str]]\n",
        "#centrality:  dict[str,float]\n",
        "\n",
        "    def norm(t: str) -> str:\n",
        "        return t.strip().lower()\n",
        "\n",
        "    if len(predictions) == 0:\n",
        "        return predictions, 0.0\n",
        "\n",
        "    # cache for new term embeddings to avoid recomputation\n",
        "    embed_cache = {}\n",
        "\n",
        "    def term_score(t: str) -> float:\n",
        "        t_norm = norm(t)\n",
        "        # centrality component (normalized to [0,1])\n",
        "        if t_norm in centrality:\n",
        "            c = centrality[t_norm]\n",
        "            c_norm = (c - c_min) / (c_max - c_min + eps) if c_max > c_min else 1.0\n",
        "        else:\n",
        "            c_norm = 0.0\n",
        "\n",
        "        # embedding similarity component: similarity to closest domain term\n",
        "        if t_norm in embed_cache:\n",
        "            vec = embed_cache[t_norm]\n",
        "        else:\n",
        "            vec = encode_terms([t_norm])\n",
        "            if vec.shape[0] == 0:\n",
        "                embed_cache[t_norm] = np.zeros((embed_model.config.hidden_size,), dtype=np.float32)\n",
        "            else:\n",
        "                embed_cache[t_norm] = vec[0]\n",
        "            vec = embed_cache[t_norm]\n",
        "\n",
        "        if domain_embs.shape[0] == 0:\n",
        "            sim = 0.0\n",
        "        else:\n",
        "            # cos sim between term and all domain terms\n",
        "            sims = domain_embs @ vec\n",
        "            sim = float(sims.max())\n",
        "            # map from [-1,1] to [0,1]\n",
        "            sim = (sim + 1.0) / 2.0\n",
        "\n",
        "        # combine weight given by using the co-occurence of terms looking at the graph and the embeddings similarity within the embedding space created\n",
        "        return float(alpha * c_norm + (1.0 - alpha) * sim)\n",
        "\n",
        "    # collect all scores to compute global threshold\n",
        "    all_scores = []\n",
        "    per_sentence_scores = []\n",
        "    for sent_terms in predictions:\n",
        "        sent_scores = []\n",
        "        for t in sent_terms:\n",
        "            s = term_score(t)\n",
        "            sent_scores.append((t, s))\n",
        "            all_scores.append(s)\n",
        "        per_sentence_scores.append(sent_scores)\n",
        "\n",
        "    if len(all_scores) == 0:\n",
        "        return predictions, 0.0\n",
        "\n",
        "    all_scores = np.array(all_scores)\n",
        "    tau = float(np.quantile(all_scores, quantile))\n",
        "\n",
        "\n",
        "    refined = []\n",
        "    for sent_scores in per_sentence_scores:\n",
        "        kept = [t for (t, s) in sent_scores if s >= tau]\n",
        "        refined.append(kept)\n",
        "\n",
        "        if len(kept) == 0 and len(sent_scores) > 0:\n",
        "          # keep the best only if it is not too far below τ\n",
        "          best_term, best_score = max(sent_scores, key=lambda x: x[1])\n",
        "          if best_score >= tau * 0.6:\n",
        "              kept = [best_term]\n",
        "          else:\n",
        "              kept = []\n",
        "\n",
        "    return refined, tau\n",
        "\n",
        "print(\"Refinement function with graph + embeddings defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fDA1DMFXZbb",
        "outputId": "a23ca900-d661-4e30-c113-fe7e9ad0dace"
      },
      "id": "4fDA1DMFXZbb",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grid search to evaluate optimal values for quantile and alpha parameters"
      ],
      "metadata": {
        "id": "nO_4PSxtbCej"
      },
      "id": "nO_4PSxtbCej"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"1. Starting Grid Search to optimize Alpha and Quantile...\")\n",
        "\n",
        "# --- HYPERPARAMETER RANGE DEFINITION ---\n",
        "# Alpha: Weight for Graph Centrality (0.0 = embedding similarity only; 1.0 = PageRank only)\n",
        "alpha_values = np.arange(0.0, 1.1, 0.1)\n",
        "# Quantile: Filtering Threshold (0.0 = no filter; 0.5 = filters the bottom 50% of scores)\n",
        "quantile_values = np.arange(0.0, 0.40, 0.05)\n",
        "\n",
        "best_f1 = -1.0\n",
        "best_params = {'alpha': None, 'quantile': None}\n",
        "results = []\n",
        "dev_gold = [s[\"terms\"]for s in dev_sentences]\n",
        "\n",
        "total_iterations = len(alpha_values) * len(quantile_values)\n",
        "print(f\"Total combinations to test: {total_iterations}\")\n",
        "\n",
        "\n",
        "#Beginning of grid search\n",
        "with tqdm(total=total_iterations, desc=\"Grid Search Progress\") as pbar:\n",
        "    for alpha in alpha_values:\n",
        "        for q in quantile_values:\n",
        "\n",
        "            # Apply the hybrid filter with the current parameters\n",
        "            # Note: refine_predictions_with_graph_and_embeddings must be defined previously\n",
        "            current_refined_preds, tau = refine_predictions_with_graph_and_embeddings(\n",
        "                predictions=crf_predictions,\n",
        "                centrality=centrality,\n",
        "                quantile=q,\n",
        "                alpha=alpha\n",
        "            )\n",
        "\n",
        "            # Evaluate the filtered output against the gold standard (dev_gold)\n",
        "            # micro_f1_score returns (P, R, F, TP, FP, FN)\n",
        "            P, R, F_, _, _, _ = micro_f1_score(dev_gold, current_refined_preds)\n",
        "\n",
        "            results.append({\n",
        "                'alpha': round(alpha, 2),\n",
        "                'quantile': round(q, 2),\n",
        "                'f1': F_,\n",
        "                'precision': P,\n",
        "                'recall': R\n",
        "            })\n",
        "\n",
        "            # Update the best parameters found so far\n",
        "            if F_ > best_f1:\n",
        "                best_f1 = F_\n",
        "                best_params['alpha'] = alpha\n",
        "                best_params['quantile'] = q\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "\n",
        "# --- FINAL REPORT ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✓ OPTIMIZATION COMPLETED!\")\n",
        "print(f\"Best F1-Score Found: {best_f1:.4f}\")\n",
        "print(f\"Optimal Parameters: Alpha={best_params['alpha']:.1f}, Quantile={best_params['quantile']:.2f}\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "# Visualization of the F1 Landscape (Heatmap)\n",
        "try:\n",
        "    df_results = pd.DataFrame(results)\n",
        "    pivot_table = df_results.pivot(index=\"quantile\", columns=\"alpha\", values=\"f1\")\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".3f\", cmap=\"viridis\")\n",
        "    plt.title(\"F1-Score Optimization Landscape (F1 vs Alpha & Quantile)\")\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(\"Suggestion: Install matplotlib and seaborn to visualize the heatmap.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c1aeb005ef834af7a8309b1597578279",
            "439d50e9233d426f990a18ff185753b0",
            "09f2b926a52346bc9ea0b53ee51f74af",
            "abb36f81b435423dbc476fcad54b49ee",
            "eb4f1d067a2f45269c1097d757980178",
            "786b6c7de3214417a2040b76941a84e5",
            "c83fcdd6d1174777b052b81cb4bf1abe",
            "7d35f4a64c4c4674b72f15933d62e6d5",
            "b2cfd1677b6e4f71af740d2c6d2355d0",
            "f8d67a1316b149179be29bf401294d1e",
            "05b4a6d30063478da093e073edece38c"
          ]
        },
        "id": "SIZNsMZfbKj_",
        "outputId": "c69b6006-60ae-4d84-9b25-14a4d20cd3cc"
      },
      "id": "SIZNsMZfbKj_",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Starting Grid Search to optimize Alpha and Quantile...\n",
            "Total combinations to test: 88\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Grid Search Progress:   0%|          | 0/88 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1aeb005ef834af7a8309b1597578279"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7297 Type Recall=0.6763 Type F1=0.7020\n",
            "Type TP=305, Type FP=113, Type FN=146\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7657 Type Recall=0.6741 Type F1=0.7170\n",
            "Type TP=304, Type FP=93, Type FN=147\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7952 Type Recall=0.6630 Type F1=0.7231\n",
            "Type TP=299, Type FP=77, Type FN=152\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8225 Type Recall=0.6475 Type F1=0.7246\n",
            "Type TP=292, Type FP=63, Type FN=159\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8263 Type Recall=0.6120 Type F1=0.7032\n",
            "Type TP=276, Type FP=58, Type FN=175\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8253 Type Recall=0.6075 Type F1=0.6999\n",
            "Type TP=274, Type FP=58, Type FN=177\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8296 Type Recall=0.5721 Type F1=0.6772\n",
            "Type TP=258, Type FP=53, Type FN=193\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8296 Type Recall=0.5721 Type F1=0.6772\n",
            "Type TP=258, Type FP=53, Type FN=193\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7297 Type Recall=0.6763 Type F1=0.7020\n",
            "Type TP=305, Type FP=113, Type FN=146\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7657 Type Recall=0.6741 Type F1=0.7170\n",
            "Type TP=304, Type FP=93, Type FN=147\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7952 Type Recall=0.6630 Type F1=0.7231\n",
            "Type TP=299, Type FP=77, Type FN=152\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8225 Type Recall=0.6475 Type F1=0.7246\n",
            "Type TP=292, Type FP=63, Type FN=159\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8263 Type Recall=0.6120 Type F1=0.7032\n",
            "Type TP=276, Type FP=58, Type FN=175\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8286 Type Recall=0.5787 Type F1=0.6815\n",
            "Type TP=261, Type FP=54, Type FN=190\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8356 Type Recall=0.5410 Type F1=0.6568\n",
            "Type TP=244, Type FP=48, Type FN=207\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8419 Type Recall=0.5078 Type F1=0.6335\n",
            "Type TP=229, Type FP=43, Type FN=222\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7297 Type Recall=0.6763 Type F1=0.7020\n",
            "Type TP=305, Type FP=113, Type FN=146\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7657 Type Recall=0.6741 Type F1=0.7170\n",
            "Type TP=304, Type FP=93, Type FN=147\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7952 Type Recall=0.6630 Type F1=0.7231\n",
            "Type TP=299, Type FP=77, Type FN=152\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8225 Type Recall=0.6475 Type F1=0.7246\n",
            "Type TP=292, Type FP=63, Type FN=159\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8263 Type Recall=0.6120 Type F1=0.7032\n",
            "Type TP=276, Type FP=58, Type FN=175\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8286 Type Recall=0.5787 Type F1=0.6815\n",
            "Type TP=261, Type FP=54, Type FN=190\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8356 Type Recall=0.5410 Type F1=0.6568\n",
            "Type TP=244, Type FP=48, Type FN=207\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8419 Type Recall=0.5078 Type F1=0.6335\n",
            "Type TP=229, Type FP=43, Type FN=222\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7297 Type Recall=0.6763 Type F1=0.7020\n",
            "Type TP=305, Type FP=113, Type FN=146\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7657 Type Recall=0.6741 Type F1=0.7170\n",
            "Type TP=304, Type FP=93, Type FN=147\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7952 Type Recall=0.6630 Type F1=0.7231\n",
            "Type TP=299, Type FP=77, Type FN=152\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8225 Type Recall=0.6475 Type F1=0.7246\n",
            "Type TP=292, Type FP=63, Type FN=159\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8263 Type Recall=0.6120 Type F1=0.7032\n",
            "Type TP=276, Type FP=58, Type FN=175\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8286 Type Recall=0.5787 Type F1=0.6815\n",
            "Type TP=261, Type FP=54, Type FN=190\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8356 Type Recall=0.5410 Type F1=0.6568\n",
            "Type TP=244, Type FP=48, Type FN=207\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8419 Type Recall=0.5078 Type F1=0.6335\n",
            "Type TP=229, Type FP=43, Type FN=222\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7297 Type Recall=0.6763 Type F1=0.7020\n",
            "Type TP=305, Type FP=113, Type FN=146\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7657 Type Recall=0.6741 Type F1=0.7170\n",
            "Type TP=304, Type FP=93, Type FN=147\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7952 Type Recall=0.6630 Type F1=0.7231\n",
            "Type TP=299, Type FP=77, Type FN=152\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8225 Type Recall=0.6475 Type F1=0.7246\n",
            "Type TP=292, Type FP=63, Type FN=159\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8263 Type Recall=0.6120 Type F1=0.7032\n",
            "Type TP=276, Type FP=58, Type FN=175\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8286 Type Recall=0.5787 Type F1=0.6815\n",
            "Type TP=261, Type FP=54, Type FN=190\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8356 Type Recall=0.5410 Type F1=0.6568\n",
            "Type TP=244, Type FP=48, Type FN=207\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8419 Type Recall=0.5078 Type F1=0.6335\n",
            "Type TP=229, Type FP=43, Type FN=222\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7297 Type Recall=0.6763 Type F1=0.7020\n",
            "Type TP=305, Type FP=113, Type FN=146\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7657 Type Recall=0.6741 Type F1=0.7170\n",
            "Type TP=304, Type FP=93, Type FN=147\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7952 Type Recall=0.6630 Type F1=0.7231\n",
            "Type TP=299, Type FP=77, Type FN=152\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8225 Type Recall=0.6475 Type F1=0.7246\n",
            "Type TP=292, Type FP=63, Type FN=159\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8263 Type Recall=0.6120 Type F1=0.7032\n",
            "Type TP=276, Type FP=58, Type FN=175\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8286 Type Recall=0.5787 Type F1=0.6815\n",
            "Type TP=261, Type FP=54, Type FN=190\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8356 Type Recall=0.5410 Type F1=0.6568\n",
            "Type TP=244, Type FP=48, Type FN=207\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8419 Type Recall=0.5078 Type F1=0.6335\n",
            "Type TP=229, Type FP=43, Type FN=222\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7297 Type Recall=0.6763 Type F1=0.7020\n",
            "Type TP=305, Type FP=113, Type FN=146\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7657 Type Recall=0.6741 Type F1=0.7170\n",
            "Type TP=304, Type FP=93, Type FN=147\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7952 Type Recall=0.6630 Type F1=0.7231\n",
            "Type TP=299, Type FP=77, Type FN=152\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8225 Type Recall=0.6475 Type F1=0.7246\n",
            "Type TP=292, Type FP=63, Type FN=159\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8263 Type Recall=0.6120 Type F1=0.7032\n",
            "Type TP=276, Type FP=58, Type FN=175\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8286 Type Recall=0.5787 Type F1=0.6815\n",
            "Type TP=261, Type FP=54, Type FN=190\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8356 Type Recall=0.5410 Type F1=0.6568\n",
            "Type TP=244, Type FP=48, Type FN=207\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8419 Type Recall=0.5078 Type F1=0.6335\n",
            "Type TP=229, Type FP=43, Type FN=222\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7297 Type Recall=0.6763 Type F1=0.7020\n",
            "Type TP=305, Type FP=113, Type FN=146\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7657 Type Recall=0.6741 Type F1=0.7170\n",
            "Type TP=304, Type FP=93, Type FN=147\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7952 Type Recall=0.6630 Type F1=0.7231\n",
            "Type TP=299, Type FP=77, Type FN=152\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8225 Type Recall=0.6475 Type F1=0.7246\n",
            "Type TP=292, Type FP=63, Type FN=159\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8263 Type Recall=0.6120 Type F1=0.7032\n",
            "Type TP=276, Type FP=58, Type FN=175\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8286 Type Recall=0.5787 Type F1=0.6815\n",
            "Type TP=261, Type FP=54, Type FN=190\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8356 Type Recall=0.5410 Type F1=0.6568\n",
            "Type TP=244, Type FP=48, Type FN=207\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8419 Type Recall=0.5078 Type F1=0.6335\n",
            "Type TP=229, Type FP=43, Type FN=222\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7297 Type Recall=0.6763 Type F1=0.7020\n",
            "Type TP=305, Type FP=113, Type FN=146\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7657 Type Recall=0.6741 Type F1=0.7170\n",
            "Type TP=304, Type FP=93, Type FN=147\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7952 Type Recall=0.6630 Type F1=0.7231\n",
            "Type TP=299, Type FP=77, Type FN=152\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8225 Type Recall=0.6475 Type F1=0.7246\n",
            "Type TP=292, Type FP=63, Type FN=159\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8263 Type Recall=0.6120 Type F1=0.7032\n",
            "Type TP=276, Type FP=58, Type FN=175\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8286 Type Recall=0.5787 Type F1=0.6815\n",
            "Type TP=261, Type FP=54, Type FN=190\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8351 Type Recall=0.5388 Type F1=0.6550\n",
            "Type TP=243, Type FP=48, Type FN=208\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8419 Type Recall=0.5078 Type F1=0.6335\n",
            "Type TP=229, Type FP=43, Type FN=222\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7297 Type Recall=0.6763 Type F1=0.7020\n",
            "Type TP=305, Type FP=113, Type FN=146\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7657 Type Recall=0.6741 Type F1=0.7170\n",
            "Type TP=304, Type FP=93, Type FN=147\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7952 Type Recall=0.6630 Type F1=0.7231\n",
            "Type TP=299, Type FP=77, Type FN=152\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8225 Type Recall=0.6475 Type F1=0.7246\n",
            "Type TP=292, Type FP=63, Type FN=159\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8263 Type Recall=0.6120 Type F1=0.7032\n",
            "Type TP=276, Type FP=58, Type FN=175\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8286 Type Recall=0.5787 Type F1=0.6815\n",
            "Type TP=261, Type FP=54, Type FN=190\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8351 Type Recall=0.5388 Type F1=0.6550\n",
            "Type TP=243, Type FP=48, Type FN=208\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8419 Type Recall=0.5078 Type F1=0.6335\n",
            "Type TP=229, Type FP=43, Type FN=222\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7297 Type Recall=0.6763 Type F1=0.7020\n",
            "Type TP=305, Type FP=113, Type FN=146\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7297 Type Recall=0.6763 Type F1=0.7020\n",
            "Type TP=305, Type FP=113, Type FN=146\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7297 Type Recall=0.6763 Type F1=0.7020\n",
            "Type TP=305, Type FP=113, Type FN=146\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7297 Type Recall=0.6763 Type F1=0.7020\n",
            "Type TP=305, Type FP=113, Type FN=146\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7297 Type Recall=0.6763 Type F1=0.7020\n",
            "Type TP=305, Type FP=113, Type FN=146\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8286 Type Recall=0.5787 Type F1=0.6815\n",
            "Type TP=261, Type FP=54, Type FN=190\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8351 Type Recall=0.5388 Type F1=0.6550\n",
            "Type TP=243, Type FP=48, Type FN=208\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.8419 Type Recall=0.5078 Type F1=0.6335\n",
            "Type TP=229, Type FP=43, Type FN=222\n",
            "\n",
            "============================================================\n",
            "✓ OPTIMIZATION COMPLETED!\n",
            "Best F1-Score Found: 0.7246\n",
            "Optimal Parameters: Alpha=0.0, Quantile=0.15\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8054e6cc",
      "metadata": {
        "id": "8054e6cc"
      },
      "source": [
        "#Evaluation metrics after using the hybrid refinement method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "85cd317f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85cd317f",
        "outputId": "2fc0d2fe-451c-4f77-a011-6ec97ed96b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refining BERT_CRF predictions on dev set using graph + embedding similarity...\n",
            "Threshold tau (quantile=0.15): 0.572282\n",
            "\n",
            "--- MICRO METRICS ---\n",
            "Precision=0.7952 Type Recall=0.6630 Type F1=0.7231\n",
            "Type TP=299, Type FP=77, Type FN=152\n",
            "\n",
            "--- TYPE-LEVEL METRICS ---\n",
            "Type Precision=0.7965 Type Recall=0.5661 Type F1=0.6618\n",
            "Type TP=137, Type FP=35, Type FN=105\n",
            "\n",
            "============================================================\n",
            "GRAPH + EMBEDDING-BASED TERM REFINEMENT RESULTS (DEV)\n",
            "============================================================\n",
            "\n",
            "Micro-averaged Metrics (after refinement):\n",
            "  Precision: 0.7952\n",
            "  Recall:    0.6630\n",
            "  F1 Score:  0.7231\n",
            "  TP=299, FP=77, FN=152\n",
            "\n",
            "Type-level Metrics (after refinement):\n",
            "  Type Precision: 0.7965\n",
            "  Type Recall:    0.5661\n",
            "  Type F1 Score:  0.6618\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "print(\"Refining BERT_CRF predictions on dev set using graph + embedding similarity...\")\n",
        "refined_preds, tau = refine_predictions_with_graph_and_embeddings(\n",
        "    crf_predictions,\n",
        "    centrality,\n",
        "    quantile=0.1,\n",
        "    alpha=0.4 # we have seen that the value of alpha doesn't change much the results\n",
        ")\n",
        "print(f\"Threshold tau (quantile=0.15): {tau:.6f}\")\n",
        "\n",
        "dev_gold = []\n",
        "\n",
        "for s in dev_sentences:\n",
        "  dev_gold.append(s[\"terms\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate refined predictions\n",
        "ref_prec, ref_rec, ref_f1, ref_tp, ref_fp, ref_fn = micro_f1_score(dev_gold, refined_preds)\n",
        "ref_type_prec, ref_type_rec, ref_type_f1 = type_f1_score(dev_gold, refined_preds)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GRAPH + EMBEDDING-BASED TERM REFINEMENT RESULTS (DEV)\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nMicro-averaged Metrics (after refinement):\")\n",
        "print(f\"  Precision: {ref_prec:.4f}\")\n",
        "print(f\"  Recall:    {ref_rec:.4f}\")\n",
        "print(f\"  F1 Score:  {ref_f1:.4f}\")\n",
        "print(f\"  TP={ref_tp}, FP={ref_fp}, FN={ref_fn}\")\n",
        "\n",
        "print(\"\\nType-level Metrics (after refinement):\")\n",
        "print(f\"  Type Precision: {ref_type_prec:.4f}\")\n",
        "print(f\"  Type Recall:    {ref_type_rec:.4f}\")\n",
        "print(f\"  Type F1 Score:  {ref_type_f1:.4f}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test set predictions"
      ],
      "metadata": {
        "id": "JrUxsmmpW-ty"
      },
      "id": "JrUxsmmpW-ty"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_raw_preds = []\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for s in test_sentences:\n",
        "        # encode sentence\n",
        "        ids, offsets = encode_for_inference(s[\"sentence_text\"], tokenizer)\n",
        "\n",
        "        # Preprocess tensors\n",
        "        inp = torch.tensor([ids]).to(device)\n",
        "        mask = torch.tensor([[1]*len(ids)]).to(device)\n",
        "\n",
        "        # Predict\n",
        "        pred = model(inp, mask)[0]\n",
        "\n",
        "        # From tags back to terms\n",
        "        predicted_terms = bio_to_terms(s[\"sentence_text\"], offsets, pred)\n",
        "        test_raw_preds.append(predicted_terms)\n",
        "\n",
        "print(f\"term predicted are {len(test_raw_preds)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Suvm0SoDXFyF",
        "outputId": "5466dd7c-29ae-434d-db46-8549728192ab"
      },
      "id": "Suvm0SoDXFyF",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "term predicted are 1141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate output format"
      ],
      "metadata": {
        "id": "zlfGmknPYEMq"
      },
      "id": "zlfGmknPYEMq"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import os.path\n",
        "from datetime import datetime\n",
        "\n",
        "# Define parameters (example values)\n",
        "OPTIMAL_QUANTILE = 0.1\n",
        "OPTIMAL_ALPHA = 0.4\n",
        "OUTPUT_DIR = \"/content/test_predictions\"\n",
        "\n",
        "def format_and_save_json(predictions_list, description):\n",
        "\n",
        "    final_output_list = []\n",
        "\n",
        "    for item, pred in zip(test_data, predictions_list):\n",
        "\n",
        "        clean_terms = list(set(t.strip().lower() for t in pred if t and t.strip()))\n",
        "\n",
        "        final_output_list.append({\n",
        "            \"document_id\": item.get(\"document_id\"),\n",
        "            \"paragraph_id\": item.get(\"paragraph_id\"),\n",
        "            \"sentence_id\": item.get(\"sentence_id\"),\n",
        "            \"term_list\": clean_terms\n",
        "        })\n",
        "\n",
        "    final_json_structure = {\"data\": final_output_list}\n",
        "\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "    filename = f\"test_preds_{description}_{timestamp}.json\"\n",
        "    output_path = os.path.join(OUTPUT_DIR, filename)\n",
        "\n",
        "\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(final_json_structure, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "print(\"✓ Submission function corrected and ready to save.\")"
      ],
      "metadata": {
        "id": "TBqBvr4NYH_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5771be5e-5db6-4817-e4d6-d5416b057f3b"
      },
      "id": "TBqBvr4NYH_H",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Submission function corrected and ready to save.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Output Predictions"
      ],
      "metadata": {
        "id": "VxfQBnc-ZIBD"
      },
      "id": "VxfQBnc-ZIBD"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Save prediction without refinement and with refinement separately \")\n",
        "\n",
        "\n",
        "\n",
        "path_baseline = format_and_save_json(\n",
        "    predictions_list=test_raw_preds,\n",
        "    description=\"BASELINE\"\n",
        ")\n",
        "print(f\"baseline): {path_baseline}\")\n",
        "\n",
        "\n",
        "#File with the application of the filter\n",
        "print(\"\\application of optimized filter (Graph + Embeddings)...\")\n",
        "\n",
        "test_refined_preds, tau = refine_predictions_with_graph_and_embeddings(\n",
        "    test_raw_preds,\n",
        "    centrality,\n",
        "    quantile=OPTIMAL_QUANTILE,\n",
        "    alpha=OPTIMAL_ALPHA\n",
        ")\n",
        "\n",
        "# Salva l'output raffinato\n",
        "path_refined = format_and_save_json(\n",
        "    predictions_list=test_refined_preds,\n",
        "    description=\"REFINED\"\n",
        ")\n",
        "print(f\"Refined implementation: {path_refined}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC0MMt5iZLbD",
        "outputId": "7cf6fd8c-0313-4eb1-c72a-0dcb6fb6334e"
      },
      "id": "vC0MMt5iZLbD",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save prediction without refinement and with refinement separately \n",
            "baseline): /content/test_predictions/test_preds_BASELINE_20251130_1734.json\n",
            "\u0007pplication of optimized filter (Graph + Embeddings)...\n",
            "Refined implementation: /content/test_predictions/test_preds_REFINED_20251130_1734.json\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c1aeb005ef834af7a8309b1597578279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_439d50e9233d426f990a18ff185753b0",
              "IPY_MODEL_09f2b926a52346bc9ea0b53ee51f74af",
              "IPY_MODEL_abb36f81b435423dbc476fcad54b49ee"
            ],
            "layout": "IPY_MODEL_eb4f1d067a2f45269c1097d757980178"
          }
        },
        "439d50e9233d426f990a18ff185753b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_786b6c7de3214417a2040b76941a84e5",
            "placeholder": "​",
            "style": "IPY_MODEL_c83fcdd6d1174777b052b81cb4bf1abe",
            "value": "Grid Search Progress: 100%"
          }
        },
        "09f2b926a52346bc9ea0b53ee51f74af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d35f4a64c4c4674b72f15933d62e6d5",
            "max": 88,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2cfd1677b6e4f71af740d2c6d2355d0",
            "value": 88
          }
        },
        "abb36f81b435423dbc476fcad54b49ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8d67a1316b149179be29bf401294d1e",
            "placeholder": "​",
            "style": "IPY_MODEL_05b4a6d30063478da093e073edece38c",
            "value": " 88/88 [03:36&lt;00:00,  2.24s/it]"
          }
        },
        "eb4f1d067a2f45269c1097d757980178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "786b6c7de3214417a2040b76941a84e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c83fcdd6d1174777b052b81cb4bf1abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d35f4a64c4c4674b72f15933d62e6d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2cfd1677b6e4f71af740d2c6d2355d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8d67a1316b149179be29bf401294d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05b4a6d30063478da093e073edece38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
